{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SHK · lit-import · v1 pipeline notebook\n",
        "\n",
        "Use this notebook to run the pipeline step‑by‑step for any corpus (KJV/ASV/WEB, Strong's, KJV+Strong's, Nicene, etc.).\n",
        "\n",
        "**Tip:** Run each cell in order. If a step fails, read the error message in the cell output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Configure paths (edit me once)\n",
        "\n",
        "- `REPO_ROOT`: absolute path to your local SHK repo\n",
        "- `LIT_IMPORT`: path to the lit-import tool\n",
        "- `API_ROOT`: output folder for the v1 API (normally `docs/data/v1`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# >>> EDIT THIS to your local checkout <<<\n",
        "REPO_ROOT = Path(r\"C:/path/to/SHK\").resolve()\n",
        "LIT_IMPORT = REPO_ROOT / \"tools/lit-import\"\n",
        "API_ROOT = REPO_ROOT / \"docs/data/v1\"\n",
        "\n",
        "REPO_ROOT, LIT_IMPORT, API_ROOT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Pick a spec (choose one)\n",
        "- Bible (plain): `bible_en_kjv_plain.json`, `bible_en_asv_plain.json`, `bible_en_web_plain.json`\n",
        "- Strong's: `strongs_lexicon.xml.json`\n",
        "- Bible + Strong's: `bible_en_kjv_plus_strongs.json`\n",
        "- General text: `exbib_en_nicene.json`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Choose one of the specs below by uncommenting it\n",
        "SPEC = LIT_IMPORT / \"src/shk_lit_import/specs/bible_en_kjv_plain.json\"\n",
        "# SPEC = LIT_IMPORT / \"src/shk_lit_import/specs/bible_en_asv_plain.json\"\n",
        "# SPEC = LIT_IMPORT / \"src/shk_lit_import/specs/bible_en_web_plain.json\"\n",
        "# SPEC = LIT_IMPORT / \"src/shk_lit_import/specs/strongs_lexicon.xml.json\"\n",
        "# SPEC = LIT_IMPORT / \"src/shk_lit_import/specs/bible_en_kjv_plus_strongs.json\"\n",
        "# SPEC = LIT_IMPORT / \"src/shk_lit_import/specs/exbib_en_nicene.json\"\n",
        "SPEC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Helper to run the CLI and show output\n",
        "This wraps `shk-lit` and captures both stdout and stderr."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess, sys, textwrap\n",
        "\n",
        "def run(cmd: list, cwd=None):\n",
        "    print(\"$\", \" \".join(cmd))\n",
        "    p = subprocess.run(cmd, cwd=cwd, text=True, capture_output=True)\n",
        "    print(p.stdout)\n",
        "    if p.returncode != 0:\n",
        "        print(p.stderr, file=sys.stderr)\n",
        "        raise RuntimeError(f\"Command failed with code {p.returncode}\")\n",
        "    return p\n",
        "\n",
        "def shk(cmd: str, extra: list = None):\n",
        "    extra = extra or []\n",
        "    return run([sys.executable, \"-m\", \"shk_lit_import.cli\", \"--spec\", str(SPEC), cmd] + extra, cwd=LIT_IMPORT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Verify environment (editable install, CLI help)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure we're pointing at the right folders\n",
        "assert LIT_IMPORT.exists(), f\"Missing: {LIT_IMPORT}\"\n",
        "assert (LIT_IMPORT / \"pyproject.toml\").exists(), \"pyproject.toml not found in tools/lit-import\"\n",
        "assert SPEC.exists(), f\"Spec not found: {SPEC}\"\n",
        "print(\"Paths look good. Now showing CLI help…\")\n",
        "shk(\"-h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) (Optional) Install the package here\n",
        "Only needed once per environment. If you already ran `pip install -e .` in your terminal, you can skip this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"], cwd=LIT_IMPORT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Fetch\n",
        "Downloads source files into `tools/lit-import/data/raw/<corpus_id>/…` and records provenance. \n",
        "**Note:** current scaffold fetcher writes a placeholder unless you fill real URLs in the spec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shk(\"fetch\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Normalize\n",
        "Parses the raw data into normalized JSONL under `tools/lit-import/data/processed/<corpus_id>/…`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shk(\"normalize\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Index (optional for plain Bible)\n",
        "Builds crosswalks/frequencies if the corpus supports them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shk(\"index\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Export pages (to docs/data/v1)\n",
        "Writes browser-facing JSON to your `docs/data/v1/**` structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shk(\"export-pages\", [\"--out\", str(API_ROOT)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Quick sanity checks (counts, manifest)\n",
        "These are convenience checks so you can confirm outputs without leaving the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json, glob\n",
        "\n",
        "def find(path_glob):\n",
        "    return [str(p) for p in glob.glob(str(path_glob), recursive=True)]\n",
        "\n",
        "print(\"API root:\", API_ROOT)\n",
        "print(\"Strong's index:\", find(API_ROOT/\"lit/strongs/index.json\"))\n",
        "print(\"KJV manifest:\", find(API_ROOT/\"lit/bible/en/kjv/manifest.json\"))\n",
        "print(\"KJV per-book files (first 5):\", find(API_ROOT/\"lit/bible/en/kjv/*.json\")[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Clean processed data (optional)\n",
        "Remove `tools/lit-import/data/processed/<corpus_id>` and re-run to verify determinism."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil, json\n",
        "spec = json.loads(Path(SPEC).read_text(encoding='utf-8'))\n",
        "corpus = spec.get('corpus_id','corpus').replace(':','_')\n",
        "proc = LIT_IMPORT / \"data/processed\" / corpus\n",
        "print(\"Removing:\", proc)\n",
        "shutil.rmtree(proc, ignore_errors=True)\n",
        "proc.exists()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Notes\n",
        "- Update the **spec** file with real URLs/sha256 to enable real fetching.\n",
        "- For KJV/ASV/WEB OSIS parsing, place an `.xml` in `tools/lit-import/data/raw/<corpus_id>/` and rerun **Normalize** → **Export**.\n",
        "- For Strong's, place the XML in `data/raw/lexicon_strongs/` (or fill `source.urls` in the spec) and run all steps."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}